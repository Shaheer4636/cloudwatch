~ $ sudo su 
bash-5.2# # 1) Do we have node CPU with NodeName dimension?
bash-5.2# aws cloudwatch list-metrics \
>   --region us-east-1 \
>   --namespace AWS/ContainerInsights \
>   --metric-name node_cpu_utilization \
>   --dimensions Name=ClusterName,Value=Strata-uat-eks-OwJIPjnj Name=NodeName,Value="*" \
>   --max-items 5
{
    "Metrics": []
}
bash-5.2# 
bash-5.2# # 2) Running pods by Namespace?
bash-5.2# aws cloudwatch list-metrics \
>   --region us-east-1 \
>   --namespace AWS/ContainerInsights \
>   --metric-name pod_number_of_running_pods \
>   --dimensions Name=ClusterName,Value=Strata-uat-eks-OwJIPjnj Name=Namespace,Value="*" \
>   --max-items 5
{
    "Metrics": []
}
bash-5.2# export AWS_REGION=us-east-1
bash-5.2# export AWS_DEFAULT_REGION=us-east-1
bash-5.2# CLUSTER="Strata-uat-eks-OwJIPjnj"
bash-5.2# 
bash-5.2# # 1) Which namespace is used? Try both.
bash-5.2# for NS in "AWS/ContainerInsights" "ContainerInsights" "CWAgent"; do
>   echo "---- $NS node_cpu_utilization (cluster-only) ----"
>   aws cloudwatch list-metrics \
>     --namespace "$NS" \
>     --metric-name node_cpu_utilization \
>     --dimensions Name=ClusterName,Value="$CLUSTER" \
>     --max-items 5
> done
---- AWS/ContainerInsights node_cpu_utilization (cluster-only) ----
{
    "Metrics": []
}
---- ContainerInsights node_cpu_utilization (cluster-only) ----
{
    "Metrics": []
}
---- CWAgent node_cpu_utilization (cluster-only) ----
{
    "Metrics": []
}
bash-5.2# 
bash-5.2# # 2) What dimensions exist for node_cpu_utilization?
bash-5.2# aws cloudwatch list-metrics \
>   --namespace AWS/ContainerInsights \
>   --metric-name node_cpu_utilization \
>   --dimensions Name=ClusterName,Value="$CLUSTER" Name=NodeName \
>   --max-items 5
{
    "Metrics": []
}
bash-5.2# 
bash-5.2# # If that returns nothing, try the other namespace too:
bash-5.2# aws cloudwatch list-metrics \
>   --namespace ContainerInsights \
>   --metric-name node_cpu_utilization \
>   --dimensions Name=ClusterName,Value="$CLUSTER" Name=NodeName \
>   --max-items 5
{
    "Metrics": []
}
bash-5.2# START=$(date -u -d '2 hours ago' +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# END=$(date -u +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# 
bash-5.2# # Try both namespaces; one will return datapoints
bash-5.2# aws cloudwatch get-metric-data \
>   --region us-east-1 \
>   --start-time "$START" --end-time "$END" \
>   --metric-data-queries '[
>     {
>       "Id":"cpu_ci",
>       "Expression":"SEARCH(\"{AWS/ContainerInsights,ClusterName=\"\"Strata-uat-eks-OwJIPjnj\"\"} MetricName=\"\"node_cpu_utilization\"\"\", \"Average\", 300)"
>     },
>     {
>       "Id":"cpu_ci_alt",
>       "Expression":"SEARCH(\"{ContainerInsights,ClusterName=\"\"Strata-uat-eks-OwJIPjnj\"\"} MetricName=\"\"node_cpu_utilization\"\"\", \"Average\", 300)"
>     }
>   ]' \
>   --query 'MetricDataResults[].{Id:Id,Points:length(Timestamps)}'

An error occurred (ValidationError) when calling the GetMetricData operation: Error in expression 'cpu_ci': Invalid syntax
bash-5.2# START=$(date -u -d '2 hours ago' +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# END=$(date -u +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# 
bash-5.2# aws cloudwatch get-metric-data \
>   --region us-east-1 \
>   --start-time "$START" --end-time "$END" \
>   --metric-data-queries '[
>     {
>       "Id":"cpu_ci",
>       "Expression":"SEARCH('{AWS/ContainerInsights,ClusterName=\"Strata-uat-eks-OwJIPjnj\",NodeName=*} MetricName=\"node_cpu_utilization\"', 'Average', 300)"
>     },
>     {
>       "Id":"cpu_ci_alt",
>       "Expression":"SEARCH('{ContainerInsights,ClusterName=\"Strata-uat-eks-OwJIPjnj\",NodeName=*} MetricName=\"node_cpu_utilization\"', 'Average', 300)"
>     }
>   ]' \
>   --query 'MetricDataResults[].{Id:Id,Points:length(Timestamps)}'

Error parsing parameter '--metric-data-queries': Invalid JSON:
[
    {
      "Id":"cpu_ci",
      "Expression":"SEARCH(AWS/ContainerInsights
bash-5.2# START=$(date -u -d '2 hours ago' +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# END=$(date -u +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# 
bash-5.2# # Try both namespaces; one will return datapoints
bash-5.2# aws cloudwatch get-metric-data \
>   --region us-east-1 \
>   --start-time "$START" --end-time "$END" \
>   --metric-data-queries '[
>     {
>       "Id":"cpu_ci",
>       "Expression":"SEARCH(\"{AWS/ContainerInsights,ClusterName=\"\"Strata-uat-eks-OwJIPjnj\"\"} MetricName=\"\"node_cpu_utilization\"\"\", \"Average\", 300)"
bash-5.2# START=$(date -u -d '2 hours ago' +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# END=$(date -u +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# 
bash-5.2# cat > queries.json <<'JSON'
> [
>   {
>     "Id": "cpu_ci",
>     "Expression": "SEARCH('{AWS/ContainerInsights,ClusterName,Strata-uat-eks-OwJIPjnj,NodeName,*} MetricName=\"node_cpu_utilization\"', 'Average', 300)"
>   },
>   {
>     "Id": "cpu_ci_alt",
>     "Expression": "SEARCH('{ContainerInsights,ClusterName,Strata-uat-eks-OwJIPjnj,NodeName,*} MetricName=\"node_cpu_utilization\"', 'Average', 300)"
>   }
> ]
> JSON
bash-5.2# 
bash-5.2# aws cloudwatch get-metric-data \
>   --region us-east-1 \
>   --start-time "$START" --end-time "$END" \
>   --metric-data-queries file://queries.json \
>   --query 'MetricDataResults[].{Id:Id,Series:length(Label),Points:length(Timestamps)}'
[]
bash-5.2# 
bash-5.2# 
bash-5.2# 
bash-5.2# 
bash-5.2# CLUSTER="Strata-uat-eks-OwJIPjnj"
bash-5.2# 
bash-5.2# # Try AWS/ContainerInsights first, fetch one NodeName
bash-5.2# NODE=$(aws cloudwatch list-metrics \
>   --region us-east-1 \
>   --namespace AWS/ContainerInsights \
>   --metric-name node_cpu_utilization \
>   --dimensions Name=ClusterName,Value="$CLUSTER" Name=NodeName \
>   --query 'Metrics[0].Dimensions[?Name==`NodeName`].Value' \
>   --output text 2>/dev/null)
bash-5.2# 
bash-5.2# NS="AWS/ContainerInsights"
bash-5.2# if [ -z "$NODE" ] || [ "$NODE" = "None" ]; then
>   NS="ContainerInsights"
>   NODE=$(aws cloudwatch list-metrics \
>     --region us-east-1 \
>     --namespace "$NS" \
bash-5.2# # Make sure kubectl is pointed at Strata-uat-eks-OwJIPjnj
bash-5.2# kubectl config current-context
error: current-context is not set
bash-5.2# kubectl get nodes -o wide
E1018 16:55:36.387170     302 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp 127.0.0.1:8080: connect: connection refused"
E1018 16:55:36.388667     302 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"http://localhost:8080/api?timeout=32s\": dial tcp 127.0.0.1:8080: connect: connection refused"
bash-5.2# set -euo pipefail
bash-5.2# 
bash-5.2# # ===== config =====
bash-5.2# REGION="us-east-1"
bash-5.2# CLUSTER="Strata-uat-eks-OwJIPjnj"
bash-5.2# DASHBOARD_NAME="Strata-uat-eks-OwJIPjnj-cloudwatch"
bash-5.2# LG_APP="/aws/containerinsights/$CLUSTER/application"

 bash-5.2# LG_HOST="/aws/containerinsights/$CLUSTER/host"
bash-5.2# LG_PERF="/aws/containerinsights/$CLUSTER/performance"
bash-5.2# STREAM="bootstrap-$(date -u +%Y%m%dT%H%M%S)"
bash-5.2# 
bash-5.2# aws configure set region "$REGION"
bash-5.2# 
bash-5.2# echo "== ensure log groups =="
== ensure log groups ==
bash-5.2# for LG in "$LG_APP" "$LG_HOST" "$LG_PERF"; do
>   aws logs create-log-group --log-group-name "$LG" 2>/dev/null || true
>   aws logs put-retention-policy --log-group-name "$LG" --retention-in-days 7 || true
> done
bash-5.2# 
bash-5.2# echo "== create stream in performance =="
== create stream in performance ==
bash-5.2# aws logs create-log-stream --log-group-name "$LG_PERF" --log-stream-name "$STREAM" 2>/dev/null || true

bash-5.2# 
bash-5.2# # helper: epoch millis
bash-5.2# now_ms() { echo $(( $(date +%s) * 1000 )); }
bash-5.2# 
bash-5.2# # ===== build a few EMF samples =====
bash-5.2# T0=$(now_ms); T1=$((T0+1)); T2=$((T0+2)); T3=$((T0+3))
bash-5.2# 
bash-5.2# # IMPORTANT: Namespace must NOT begin with AWS/ for custom metrics
bash-5.2# # We publish into "ContainerInsights" to mirror CI names/dimensions.
bash-5.2# cat > emf.jsonl <<EOF
> {"_aws":{"Timestamp":$T0,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","NodeName"]],"Metrics":[{"Name":"node_cpu_utilization","Unit":"Percent"},{"Name":"node_memory_utilization","Unit":"Percent"},{"Name":"node_filesystem_utilization","Unit":"Percent"}]}]},"ClusterName":"$CLUSTER","NodeName":"demo-node-1","node_cpu_utilization":23.4,"node_memory_utilization":61.2,"node_filesystem_utilization":48.7}
> {"_aws":{"Timestamp":$T1,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","NodeName"]],"Metrics":[{"Name":"node_cpu_utilization","Unit":"Percent"},{"Name":"node_memory_utilization","Unit":"Percent"},{"Name":"node_filesystem_utilization","Unit":"Percent"}]}]},"ClusterName":"$CLUSTER","NodeName":"demo-node-2","node_cpu_utilization":17.9,"node_memory_utilization":42.0,"node_filesystem_utilization":55.1}
> {"_aws":{"Timestamp":$T2,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","Namespace"]],"Metrics":[{"Name":"pod_number_of_running_pods","Unit":"Count"}]}]},"ClusterName":"$CLUSTER","Namespace":"kube-system","pod_number_of_running_pods":42}
> {"_aws":{"Timestamp":$T3,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","Namespace"]],"Metrics":[{"Name":"pod_number_of_running_pods","Unit":"Count"}]}]},"ClusterName":"$CLUSTER","Namespace":"default","pod_number_of_running_pods":15}
> EOF
bash-5.2# 
bash-5.2# # Turn the JSON lines into the structure CloudWatch Logs expects
bash-5.2# cat > events.json <<EOF
> [
>   {"timestamp": $T0, "message": "$(sed -n '1p' emf.jsonl | tr -d '\n' )"},
>   {"timestamp": $T1, "message": "$(sed -n '2p' emf.jsonl | tr -d '\n' )"},
>   {"timestamp": $T2, "message": "$(sed -n '3p' emf.jsonl | tr -d '\n' )"},
>   {"timestamp": $T3, "message": "$(sed -n '4p' emf.jsonl | tr -d '\n' )"}
> ]
> EOF
bash-5.2# 
bash-5.2# echo "== put EMF events =="
== put EMF events ==
bash-5.2# aws logs put-log-events \
>   --log-group-name "$LG_PERF" \
>   --log-stream-name "$STREAM" \
>   --log-events file://events.json >/dev/null

Error parsing parameter '--log-events': Invalid JSON: Expecting ',' delimiter: line 2 column 46 (char 47)
JSON received: [
  {"timestamp": 1760806736000, "message": "{"_aws":{"Timestamp":1760806736000,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","NodeName"]],"Metrics":[{"Name":"node_cpu_utilization","Unit":"Percent"},{"Name":"node_memory_utilization","Unit":"Percent"},{"Name":"node_filesystem_utilization","Unit":"Percent"}]}]},"ClusterName":"Strata-uat-eks-OwJIPjnj","NodeName":"demo-node-1","node_cpu_utilization":23.4,"node_memory_utilization":61.2,"node_filesystem_utilization":48.7}"},
  {"timestamp": 1760806736001, "message": "{"_aws":{"Timestamp":1760806736001,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","NodeName"]],"Metrics":[{"Name":"node_cpu_utilization","Unit":"Percent"},{"Name":"node_memory_utilization","Unit":"Percent"},{"Name":"node_filesystem_utilization","Unit":"Percent"}]}]},"ClusterName":"Strata-uat-eks-OwJIPjnj","NodeName":"demo-node-2","node_cpu_utilization":17.9,"node_memory_utilization":42.0,"node_filesystem_utilization":55.1}"},
  {"timestamp": 1760806736002, "message": "{"_aws":{"Timestamp":1760806736002,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","Namespace"]],"Metrics":[{"Name":"pod_number_of_running_pods","Unit":"Count"}]}]},"ClusterName":"Strata-uat-eks-OwJIPjnj","Namespace":"kube-system","pod_number_of_running_pods":42}"},
  {"timestamp": 1760806736003, "message": "{"_aws":{"Timestamp":1760806736003,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","Namespace"]],"Metrics":[{"Name":"pod_number_of_running_pods","Unit":"Count"}]}]},"ClusterName":"Strata-uat-eks-OwJIPjnj","Namespace":"default","pod_number_of_running_pods":15}"}
]

~ $ 
~ $ ^C
~ $ 
~ $ 
~ $ 
~ $ sudo su 
bash-5.2# set -euo pipefail
bash-5.2# REGION=us-east-1
bash-5.2# CLUSTER=Strata-uat-eks-OwJIPjnj
bash-5.2# LG_PERF="/aws/containerinsights/$CLUSTER/performance"
bash-5.2# STREAM="bootstrap-$(date -u +%Y%m%dT%H%M%S)"
bash-5.2# 
bash-5.2# aws logs create-log-group --log-group-name "$LG_PERF" 2>/dev/null || true
bash-5.2# aws logs put-retention-policy --log-group-name "$LG_PERF" --retention-in-days 7 || true
bash-5.2# aws logs create-log-stream --log-group-name "$LG_PERF" --log-stream-name "$STREAM" 2>/dev/null || true
bash-5.2# 
bash-5.2# # helper timestamp (ms)
bash-5.2# now_ms() { echo $(( $(date +%s) * 1000 )); }
bash-5.2# T0=$(now_ms); T1=$((T0+1)); T2=$((T0+2)); T3=$((T0+3))
bash-5.2# 
bash-5.2# # 1) Write 4 EMF lines (UNescaped) to a file
bash-5.2# cat > emf.jsonl <<EOF
> {"_aws":{"Timestamp":$T0,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","NodeName"]],"Metrics":[{"Name":"node_cpu_utilization","Unit":"Percent"},{"Name":"node_memory_utilization","Unit":"Percent"},{"Name":"node_filesystem_utilization","Unit":"Percent"}]}]},"ClusterName":"$CLUSTER","NodeName":"demo-node-1","node_cpu_utilization":23.4,"node_memory_utilization":61.2,"node_filesystem_utilization":48.7}
> {"_aws":{"Timestamp":$T1,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","NodeName"]],"Metrics":[{"Name":"node_cpu_utilization","Unit":"Percent"},{"Name":"node_memory_utilization","Unit":"Percent"},{"Name":"node_filesystem_utilization","Unit":"Percent"}]}]},"ClusterName":"$CLUSTER","NodeName":"demo-node-2","node_cpu_utilization":17.9,"node_memory_utilization":42.0,"node_filesystem_utilization":55.1}
> {"_aws":{"Timestamp":$T2,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","Namespace"]],"Metrics":[{"Name":"pod_number_of_running_pods","Unit":"Count"}]}]},"ClusterName":"$CLUSTER","Namespace":"kube-system","pod_number_of_running_pods":42}
> {"_aws":{"Timestamp":$T3,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","Namespace"]],"Metrics":[{"Name":"pod_number_of_running_pods","Unit":"Count"}]}]},"ClusterName":"$CLUSTER","Namespace":"default","pod_number_of_running_pods":15}
> EOF
bash-5.2# 
bash-5.2# # 2) Escape each line as a JSON string using jq (so message is valid)
bash-5.2# MSG1=$(sed -n '1p' emf.jsonl | jq -Rs .)
bash-5.2# MSG2=$(sed -n '2p' emf.jsonl | jq -Rs .)
bash-5.2# MSG3=$(sed -n '3p' emf.jsonl | jq -Rs .)
bash-5.2# MSG4=$(sed -n '4p' emf.jsonl | jq -Rs .)
bash-5.2# 
bash-5.2# cat > events.json <<EOF
> [
>   {"timestamp": $T0, "message": $MSG1},
>   {"timestamp": $T1, "message": $MSG2},
>   {"timestamp": $T2, "message": $MSG3},
>   {"timestamp": $T3, "message": $MSG4}
> ]
> EOF
bash-5.2# 
bash-5.2# # 3) Put EMF events (all in one call)
bash-5.2# aws logs put-log-events \
>   --log-group-name "$LG_PERF" \
>   --log-stream-name "$STREAM" \
>   --log-events file://events.json
{
    "nextSequenceToken": "49668028670044967956835501843464904602700390612831569090"
}
bash-5.2# 
bash-5.2# # 4) Verify EMF is in the log group
bash-5.2# aws logs filter-log-events \
>   --log-group-name "$LG_PERF" --limit 1 \
>   --query 'events[0].message'
"{\"_aws\":{\"Timestamp\":1760806918000,\"CloudWatchMetrics\":[{\"Namespace\":\"ContainerInsights\",\"Dimensions\":[[\"ClusterName\",\"NodeName\"]],\"Metrics\":[{\"Name\":\"node_cpu_utilization\",\"Unit\":\"Percent\"},{\"Name\":\"node_memory_utilization\",\"Unit\":\"Percent\"},{\"Name\":\"node_filesystem_utilization\",\"Unit\":\"Percent\"}]}]},\"ClusterName\":\"Strata-uat-eks-OwJIPjnj\",\"NodeName\":\"demo-node-1\",\"node_cpu_utilization\":23.4,\"node_memory_utilization\":61.2,\"node_filesystem_utilization\":48.7}\n"
bash-5.2# 
bash-5.2# 
bash-5.2# 
bash-5.2# START=$(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# END=$(date -u +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# 
bash-5.2# cat > queries.json <<'JSON'
> [
>   {
>     "Id": "cpu",
>     "Expression": "SEARCH('{ContainerInsights,ClusterName,Strata-uat-eks-OwJIPjnj,NodeName,*} MetricName=\"node_cpu_utilization\"', 'Average', 300)"
>   },
>   {
>     "Id": "pods",
>     "Expression": "SEARCH('{ContainerInsights,ClusterName,Strata-uat-eks-OwJIPjnj,Namespace,*} MetricName=\"pod_number_of_running_pods\"', 'Sum', 300)"
>   }
> ]
> JSON
bash-5.2# 
bash-5.2# aws cloudwatch get-metric-data \
>   --region us-east-1 \
>   --start-time "$START" --end-time "$END" \
>   --metric-data-queries file://queries.json \
>   --query 'MetricDataResults[].{Id:Id,Points:length(Timestamps)}'
[]
bash-5.2# 
bash-5.2# 
bash-5.2# sed -i 's/"AWS\/ContainerInsights"/"ContainerInsights"/g' dashboard.json
sed: can't read dashboard.json: No such file or directory
~ $ 
~ $ ls
emf.jsonl  events.json  k8s-daemonsets.json  mqdashboard.json  queries.json
~ $ #!/usr/bin/env bash
~ $ set -euo pipefail
~ $ 
n~ $ # ==== Fixed to your inputs ====
~ $ REGION="us-east-1"
a~ $ CLUSTER="Strata-uat-eks-OwJIPjnj"
~ $ DASHBOARD_NAME="Strata-uat-eks-OwJIPjnj -cloudwatch"
~ $ NS="AWS/ContainerInsights"
~ $ PERIOD=300
~ $ # ==============================
~ $ 
"~ $ echo "Region: $REGION"
Region: us-east-1
~ $ echo "Cluster: $CLUSTER"
Cluster: Strata-uat-eks-OwJIPjnj
~ $ echo "Dashboard: $DASHBOARD_NAME"
wDashboard: Strata-uat-eks-OwJIPjnj -cloudwatch
~ $ 
"~ $ echo "Sanity check: Container Insights metrics present?"
trSanity check: Container Insights metrics present?
~ $ aws cloudwatch list-metrics \
ntain>   --region "$REGION" \
o>   --namespace "$NS" \
N>   --dimensions Name=ClusterName,Value="$CLUSTER" \
>   --max-items 5
{"
    "Metrics": []
}
~ $ 
~ $ # Try to detect Container Insights log groups (for Logs Insights widgets)
~ $ APP_LG="/aws/containerinsights/${CLUSTER}/application"
~ $ INFRA_LG="/aws/containerinsights/${CLUSTER}/host"
~ $ PERF_LG="/aws/containerinsights/${CLUSTER}/performance"
~ $ for lg in "$APP_LG" "$INFRA_LG" "$PERF_LG"; do
>   aws logs describe-log-groups --region "$REGION" --log-group-name-prefix "$lg" --max-items 1 >/dev/null 2>&1 || true
"x":12,"y":20,"width":12,"height":6,
      "properties":{"region":"REGION","title":"Node disk IO (read/write bytes) per node","view":"timeSeries","stat":"Sum","period":PERIOD,
        "metrics":[
          ["AWS/ContainerInsights","node_diskio_read_bytes","ClusterName","CLUSTER","Node> done
~ $ 
~ $ # Build dashboard
~ $ cat > dashboard.json <<'JSON'
> {
>   "widgets": [
>     { "type":"text","x":0,"y":0,"width":24,"height":2,
>       "properties":{"markdown":"# EKS – Strata-uat-eks-OwJIPjnj (CloudWatch) \nCluster overview, health, capacity and workload state using **AWS/ContainerInsights**."}
>     },
> 
>     /* ===== Cluster Health ===== */
>     { "type":"metric","x":0,"y":2,"width":8,"height":6,
>       "properties":{"region":"REGION","title":"Cluster CPU utilization (%)","view":"timeSeries","stat":"Average","period":PERIOD,
>         "yAxis":{"left":{"min":0,"max":100,"label":"%"}},
>         "metrics":[["AWS/ContainerInsights","node_cpu_utilization","ClusterName","CLUSTER",{"label":"CPU %"}]]
>     }},
>     { "type":"metric","x":8,"y":2,"width":8,"height":6,
>       "properties":{"region":"REGION","title":"Cluster Memory utilization (%)","view":"timeSeries","stat":"Average","period":PERIOD,
>         "yAxis":{"left":{"min":0,"max":100,"label":"%"}},
>         "metrics":[["AWS/ContainerInsights","node_memory_utilization","ClusterName","CLUSTER",{"label":"Mem %"}]]
>     }},
">     { "type":"metric","x":16,"y":2,"width":8,"height":6,
>       "properties":{"region":"REGION","title":"Cluster Filesystem utilization (%)","view":"timeSeries","stat":"Average","period":PERIOD,
>         "yAxis":{"left":{"min":0,"max":100,"label":"%"}},
>         "metrics":[["AWS/ContainerInsights","node_filesystem_utilization","ClusterName","CLUSTER",{"label":"FS %"}]]
>     }},
> 
h>     /* ===== Pod Phase / Counts ===== */
>     { "type":"metric","x":0,"y":8,"width":12,"height":6,
>       "properties":{"region":"REGION","title":"Pods by phase (running/pending/failed/etc)","view":"timeSeries","stat":"Sum","period":PERIOD,
>         "metrics":[
>           ["AWS/ContainerInsights","pod_number_of_running_pods","ClusterName","CLUSTER",{"label":"running"}],
>           [".","pod_number_of_pending_pods",".","CLUSTER",{"label":"pending"}],
>           [".","pod_number_of_failed_pods",".","CLUSTER",{"label":"failed"}],
>           [".","pod_number_of_unknown_pods",".","CLUSTER",{"label":"unknown"}],
>           [".","pod_number_of_succeeded_pods",".","CLUSTER",{"label":"succeeded"}]
>         ]
ght>     }},
>     { "type":"metric","x":12,"y":8,"width":12,"height":6,
>       "properties":{"region":"REGION","title":"Running pods by namespace","view":"timeSeries","stat":"Sum","period":PERIOD,
ION>         "metrics":[["AWS/ContainerInsights","pod_number_of_running_pods","ClusterName","CLUSTER","Namespace","*",{"label":"namespace"}]]
>     }},
> 
>     /* ===== Nodes (per-node CPU/Mem) ===== */
>     { "type":"metric","x":0,"y":14,"width":12,"height":6,
>       "properties":{"region":"REGION","title":"Node CPU utilization (%) by node","view":"timeSeries","stat":"Average","period":PERIOD,
>         "yAxis":{"left":{"min":0,"max":100,"label":"%"}},
>         "metrics":[["AWS/ContainerInsights","node_cpu_utilization","ClusterName","CLUSTER","NodeName","*",{"label":"node"}]]
>     }},
>     { "type":"metric","x":12,"y":14,"width":12,"height":6,
>       "properties":{"region":"REGION","title":"Node Memory utilization (%) by node","view":"timeSeries","stat":"Average","period":PERIOD,
>         "yAxis":{"left":{"min":0,"max":100,"label":"%"}},
>         "metrics":[["AWS/ContainerInsights","node_memory_utilization","ClusterName","CLUSTER","NodeName","*",{"label":"node"}]]
>     }},
> 
>     /* ===== Network / Disk ===== */
>     { "type":"metric","x":0,"y":20,"width":12,"height":6,
>       "properties":{"region":"REGION","title":"Node network bytes (rx/tx) per node","view":"timeSeries","stat":"Sum","period":PERIOD,
>         "metrics":[
>           ["AWS/ContainerInsights","node_network_rx_bytes","ClusterName","CLUSTER","NodeName","*",{"label":"rx_bytes"}],
>           [".","node_network_tx_bytes",".","CLUSTER","NodeName","*",{"label":"tx_bytes"}]
>         ]
    >     }},
>     { "type":"metric","x":12,"y":20,"width":12,"height":6,
>       "properties":{"region":"REGION","title":"Node disk IO (read/write bytes) per node","view":"timeSeries","stat":"Sum","period":PERIOD,
>         "metrics":[
>           ["AWS/ContainerInsights","node_diskio_read_bytes","ClusterName","CLUSTER","NodeName","*",{"label":"read"}],
>           [".","node_diskio_write_bytes",".","CLUSTER","NodeName","*",{"label":"write"}]
>         ]
>     }},
> 
>     /* ===== Containers (utilization, restarts) ===== */
>     { "type":"metric","x":0,"y":26,"width":12,"height":6,
>       "properties":{"region":"REGION","title":"Container CPU utilization (%) by container","view":"timeSeries","stat":"Average","period":PERIOD,
>         "yAxis":{"left":{"min":0,"max":100,"label":"%"}},
>         "metrics":[["AWS/ContainerInsights","container_cpu_utilization","ClusterName","CLUSTER","ContainerName","*",{"label":"container"}]]
>     }},
>     { "type":"metric","x":12,"y":26,"width":12,"height":6,
>       "properties":{"region":"REGION","title":"Container Memory utilization (%) by container","view":"timeSeries","stat":"Average","period":PERIOD,
>         "yAxis":{"left":{"min":0,"max":100,"label":"%"}},
>         "metrics":[["AWS/ContainerInsights","container_memory_utilization","ClusterName","CLUSTER","ContainerName","*",{"label":"container"}]]
>     }},
>     { "type":"metric","x":0,"y":32,"width":12,"height":6,
>       "properties":{"region":"REGION","title":"Container restarts by pod (approx)","view":"timeSeries","stat":"Sum","period":PERIOD,
>         "metrics":[["AWS/ContainerInsights","container_restart_count","ClusterName","CLUSTER","PodName","*",{"label":"restarts"}]]
>     }},
> 
>     /* ===== Logs Insights: Kubernetes events ===== */
~ $ 
~ $ 
~ $ sudo su 
bash-5.2# set -euo pipefail
bash-5.2# REGION=us-east-1
bash-5.2# CLUSTER=Strata-uat-eks-OwJIPjnj
bash-5.2# LG_PERF="/aws/containerinsights/$CLUSTER/performance"
bash-5.2# STREAM="bootstrap-$(date -u +%Y%m%dT%H%M%S)"
bash-5.2# 
bash-5.2# aws logs create-log-group --log-group-name "$LG_PERF" 2>/dev/null || true
bash-5.2# aws logs put-retention-policy --log-group-name "$LG_PERF" --retention-in-days 7 || true
bash-5.2# aws logs create-log-stream --log-group-name "$LG_PERF" --log-stream-name "$STREAM" 2>/dev/null || true
bash-5.2# 
bash-5.2# # helper timestamp (ms)
bash-5.2# now_ms() { echo $(( $(date +%s) * 1000 )); }
bash-5.2# T0=$(now_ms); T1=$((T0+1)); T2=$((T0+2)); T3=$((T0+3))
bash-5.2# 
bash-5.2# # 1) Write 4 EMF lines (UNescaped) to a file
bash-5.2# cat > emf.jsonl <<EOF
> {"_aws":{"Timestamp":$T0,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","NodeName"]],"Metrics":[{"Name":"node_cpu_utilization","Unit":"Percent"},{"Name":"node_memory_utilization","Unit":"Percent"},{"Name":"node_filesystem_utilization","Unit":"Percent"}]}]},"ClusterName":"$CLUSTER","NodeName":"demo-node-1","node_cpu_utilization":23.4,"node_memory_utilization":61.2,"node_filesystem_utilization":48.7}
> {"_aws":{"Timestamp":$T1,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","NodeName"]],"Metrics":[{"Name":"node_cpu_utilization","Unit":"Percent"},{"Name":"node_memory_utilization","Unit":"Percent"},{"Name":"node_filesystem_utilization","Unit":"Percent"}]}]},"ClusterName":"$CLUSTER","NodeName":"demo-node-2","node_cpu_utilization":17.9,"node_memory_utilization":42.0,"node_filesystem_utilization":55.1}
> {"_aws":{"Timestamp":$T2,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","Namespace"]],"Metrics":[{"Name":"pod_number_of_running_pods","Unit":"Count"}]}]},"ClusterName":"$CLUSTER","Namespace":"kube-system","pod_number_of_running_pods":42}
> {"_aws":{"Timestamp":$T3,"CloudWatchMetrics":[{"Namespace":"ContainerInsights","Dimensions":[["ClusterName","Namespace"]],"Metrics":[{"Name":"pod_number_of_running_pods","Unit":"Count"}]}]},"ClusterName":"$CLUSTER","Namespace":"default","pod_number_of_running_pods":15}
> EOF
bash-5.2# 
bash-5.2# # 2) Escape each line as a JSON string using jq (so message is valid)
bash-5.2# MSG1=$(sed -n '1p' emf.jsonl | jq -Rs .)
bash-5.2# MSG2=$(sed -n '2p' emf.jsonl | jq -Rs .)
bash-5.2# MSG3=$(sed -n '3p' emf.jsonl | jq -Rs .)
bash-5.2# MSG4=$(sed -n '4p' emf.jsonl | jq -Rs .)
bash-5.2# 
bash-5.2# cat > events.json <<EOF
> [
>   {"timestamp": $T0, "message": $MSG1},
>   {"timestamp": $T1, "message": $MSG2},
>   {"timestamp": $T2, "message": $MSG3},
>   {"timestamp": $T3, "message": $MSG4}
> ]
> EOF
bash-5.2# 
bash-5.2# # 3) Put EMF events (all in one call)
bash-5.2# aws logs put-log-events \
>   --log-group-name "$LG_PERF" \
>   --log-stream-name "$STREAM" \
>   --log-events file://events.json
{
    "nextSequenceToken": "49665900446418149854063284147110448050342536536697865666"
}
bash-5.2# 
bash-5.2# # 4) Verify EMF is in the log group
bash-5.2# aws logs filter-log-events \
>   --log-group-name "$LG_PERF" --limit 1 \
>   --query 'events[0].message'
"{\"_aws\":{\"Timestamp\":1760806918000,\"CloudWatchMetrics\":[{\"Namespace\":\"ContainerInsights\",\"Dimensions\":[[\"ClusterName\",\"NodeName\"]],\"Metrics\":[{\"Name\":\"node_cpu_utilization\",\"Unit\":\"Percent\"},{\"Name\":\"node_memory_utilization\",\"Unit\":\"Percent\"},{\"Name\":\"node_filesystem_utilization\",\"Unit\":\"Percent\"}]}]},\"ClusterName\":\"Strata-uat-eks-OwJIPjnj\",\"NodeName\":\"demo-node-1\",\"node_cpu_utilization\":23.4,\"node_memory_utilization\":61.2,\"node_filesystem_utilization\":48.7}\n"
bash-5.2# 
bash-5.2# 
bash-5.2# 
bash-5.2# 
bash-5.2# 
bash-5.2# 
bash-5.2# 
bash-5.2# START=$(date -u -d '30 minutes ago' +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# END=$(date -u +%Y-%m-%dT%H:%M:%SZ)
bash-5.2# 
bash-5.2# cat > queries.json <<'JSON'
> [
>   {
>     "Id": "cpu",
>     "Expression": "SEARCH('{ContainerInsights,ClusterName,Strata-uat-eks-OwJIPjnj,NodeName,*} MetricName=\"node_cpu_utilization\"', 'Average', 300)"
>   },
>   {
>     "Id": "pods",
>     "Expression": "SEARCH('{ContainerInsights,ClusterName,Strata-uat-eks-OwJIPjnj,Namespace,*} MetricName=\"pod_number_of_running_pods\"', 'Sum', 300)"
>   }
> ]
> JSON
bash-5.2# 
bash-5.2# aws cloudwatch get-metric-data \
>   --region us-east-1 \
>   --start-time "$START" --end-time "$END" \
>   --metric-data-queries file://queries.json \
>   --query 'MetricDataResults[].{Id:Id,Points:length(Timestamps)}'
[]
bash-5.2# 
bash-5.2# 
bash-5.2# 
bash-5.2# 
bash-5.2# 
bash-5.2# sed -i 's/"AWS\/ContainerInsights"/"ContainerInsights"/g' dashboard.json
bash-5.2# aws cloudwatch put-dashboard \
>   --region us-east-1 \
>   --dashboard-name "Strata-uat-eks-OwJIPjnj-cloudwatch" \
>   --dashboard-body file://dashboard.json

An error occurred (InvalidParameterInput) when calling the PutDashboard operation: The field DashboardBody must be a valid JSON object
~ $ 
~ $ 
~ $ 
~ $ 
